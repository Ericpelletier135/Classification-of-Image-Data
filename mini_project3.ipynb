{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Mini Project 3"
      ],
      "metadata": {
        "id": "BWl6uLmXb45c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5nWzqUBhX-Ne"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "%matplotlib notebook\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 1: Acquire the data"
      ],
      "metadata": {
        "id": "vvG0tVevcFHc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "load dataset using tensorflow library"
      ],
      "metadata": {
        "id": "Z6ZmhX89eH67"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "X_train.shape\n",
        "print(len(X_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXIElQFMcHo2",
        "outputId": "8527432c-bdd7-4315-df18-6a31f3df45a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n",
            "60000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We start by transforming the training and test sets into a 1D array. \n",
        "\n"
      ],
      "metadata": {
        "id": "ZbFsmq4ZimIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_arr = []\n",
        "for i in range(len(y_train)):\n",
        "  y_train_zeros = np.zeros(9)\n",
        "  a = np.insert(y_train_zeros, y_train[i], 1)\n",
        "  y_train_arr.append(a)\n"
      ],
      "metadata": {
        "id": "vcfGoHi8ySIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.copy(X_train)\n",
        "X_train_f = X_train.astype(np.float64)\n",
        "X_train_f -= np.mean(X_train_f)\n",
        "X_train_f /= np.std(X_train_f)\n",
        "\n",
        "X_test = np.copy(X_test)\n",
        "X_test_f = X_test.astype(np.float64)\n",
        "X_test_f -= np.mean(X_test_f)\n",
        "X_test_f /= np.std(X_test_f)\n",
        "\n",
        "X_train_vect = X_train.reshape(X_train_f.shape[0], (X_train_f.shape[1]*X_train_f.shape[2]))\n",
        "X_test_vect = X_test.reshape(X_test_f.shape[0], (X_test_f.shape[1]*X_test_f.shape[2]))\n",
        "from matplotlib import pyplot\n",
        "pyplot.imshow(X_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "Bogsga1Vit-5",
        "outputId": "7e2d0b30-337b-49bb-d1ff-e8b02c8508bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-0dbea21722ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_train_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX_train_f\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_train_f\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2: Implement a Multilayer Perceptron"
      ],
      "metadata": {
        "id": "QIgj8Q4f4FlN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multilayer Perceptron Class (to be finished)"
      ],
      "metadata": {
        "id": "o_5j7HXN0axr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#define activation functions and their derivatives\n",
        "def relu(x):\n",
        "  return 0.0 if x < 0.0 else x\n",
        "relu_v = np.vectorize(relu)\n",
        "def relu_deriv(x):\n",
        "  return 0.0 if x < 0.0 else 1.0\n",
        "relu_deriv_v = np.vectorize(relu_deriv)\n",
        "def leaky_relu(x):\n",
        "  return 0.1 * x if x < 0 else x\n",
        "leaky_relu_v = np.vectorize(leaky_relu)\n",
        "def leaky_deriv(x):\n",
        "  return 0.1 if x < 0 else 1\n",
        "leaky_deriv_v = np.vectorize(leaky_deriv)\n",
        "def tanh(x):\n",
        "  return np.tanh(x)\n",
        "tanh_v = np.vectorize(tanh)\n",
        "def tanh_deriv(x):\n",
        "  return 0.1 - np.tanh(x)**2\n",
        "tanh_deriv_v = np.vectorize(tanh_deriv)\n",
        "\n",
        "def softmax(x):\n",
        "  e_x = np.exp(x - np.max(x))\n",
        "  return e_x / e_x.sum(axis=0)\n",
        "\n",
        "def cross_entropy(yh, y):\n",
        "    if y == 1.0:\n",
        "      return -np.log(yh)\n",
        "    else:\n",
        "      return -np.log(1 - yh)\n",
        "\n",
        "def log_softmax(x):\n",
        "    c = x.max()\n",
        "    logsumexp = np.log(np.exp(x - c).sum())\n",
        "    return x - c - logsumexp\n",
        "\n",
        "\n",
        "class MultilayerPerceptron:\n",
        "    \n",
        "    def __init__(self, activation_function, activation_derivative, num_hidden_layers, num_units_hidden_layers):\n",
        "      self.activation_function = activation_function\n",
        "      self.activation_derivative = activation_derivative\n",
        "      self.num_hidden_layers = num_hidden_layers\n",
        "      self.num_units_hidden_layers = num_units_hidden_layers\n",
        "      D = [28,28]\n",
        "      C = 9\n",
        "      # initialize weights and bias' randomly\n",
        "      hidden_layers = []\n",
        "      for i in range(num_hidden_layers):\n",
        "        hidden_layers.append(num_units_hidden_layers)\n",
        "      \n",
        "      layers = [2] + hidden_layers + [1]\n",
        "\n",
        "      weights = []\n",
        "      bias = []\n",
        "      for i in range(len(layers) - 1):\n",
        "        w = np.random.randn(layers[i], layers[i + 1]) * 0.01\n",
        "        weights.append(w)\n",
        "        b = np.full(layers[i + 1], 0.1)\n",
        "        bias.append(b)\n",
        "      self.weights = weights\n",
        "      self.bias = bias\n",
        "\n",
        "\n",
        "      activations = []\n",
        "      for i in range(len(layers)):\n",
        "        a = np.zeros(layers[i])\n",
        "        activations.append(a)\n",
        "      self.activations = activations\n",
        "\n",
        "      derivatives = [] \n",
        "      for i in range(len(layers) - 1):\n",
        "        d = np.zeros((layers[i], layers[i+1]))\n",
        "        derivatives.append(d)\n",
        "      self.derivatives = derivatives\n",
        "\n",
        "    def forward_propagate(self, inputs):\n",
        "      activations = inputs\n",
        "      self.activations[0] = inputs\n",
        "\n",
        "      for i, w in enumerate(self.weights):\n",
        "        b = self.bias[i]\n",
        "        \n",
        "        net_inputs = np.dot(activations, w) \n",
        "\n",
        "        # print(net_inputs)\n",
        "\n",
        "        # apply activation function\n",
        "        activations = self.activation_function(net_inputs)\n",
        "        # if(i == len(self.weights) - 1):\n",
        "        #   activations = softmax(activations)\n",
        "\n",
        "        # print(activations)\n",
        "        self.activations[i+1] = activations\n",
        "\n",
        "      return activations\n",
        "\n",
        "    def back_propagate(self, error):\n",
        "      for i in reversed(range(len(self.derivatives))):\n",
        "        activations = self.activations[i+1]\n",
        "        delta = error * self.activation_derivative(activations) \n",
        "        delta_reshaped = delta.reshape(delta.shape[0], -1).T     #1D array to 2D array with single row\n",
        "        current_activations = self.activations[i] \n",
        "        current_activations_reshaped = current_activations.reshape(current_activations.shape[0], -1) #1D array to 2D array with multiple rows\n",
        "\n",
        "        self.derivatives[i] = np.dot(current_activations_reshaped, delta_reshaped)\n",
        "        error = np.dot(delta, self.weights[i].T)\n",
        "      \n",
        "\n",
        "\n",
        "    # need to add bias\n",
        "    def gradient_descent(self, learning_rate):\n",
        "      for i in range(len(self.weights)):\n",
        "        weigths = self.weights[i]\n",
        "        derivatives = self.derivatives[i]\n",
        "        weigths += derivatives * learning_rate\n",
        "\n",
        "    def fit(self, inputs, targets, learning_rate, num_of_iterations):\n",
        "\n",
        "      for i in range(num_of_iterations):\n",
        "        # iterate through every input and its target one by one\n",
        "        for x, y in zip(inputs, targets):\n",
        "          #forward propagate\n",
        "          output = self.forward_propagate(x)\n",
        "\n",
        "          #calculate error\n",
        "          # error = 0\n",
        "          # for i in range(len(output)):\n",
        "          #   output[i] = max(1e-9, output[i])\n",
        "\n",
        "          # error = -np.sum(y * np.log(output))\n",
        "          # error = np.log(error)\n",
        "          # for i in range(len(y)):\n",
        "          #   val = cross_entropy(output[i], y[i])\n",
        "          #   error += val\n",
        "\n",
        "          error = y - output\n",
        "\n",
        "          #back propagate\n",
        "          self.back_propagate(error)\n",
        "\n",
        "          self.gradient_descent(learning_rate)\n",
        "      \n",
        "    def predict(self, inputs):\n",
        "      # predictions = []\n",
        "      for x in inputs:\n",
        "        prediction = self.forward_propagate(x)    \n",
        "        print(prediction)\n",
        "      #   predictions.append(prediction)\n",
        "      # return predictions\n",
        "\n",
        "    def evaluate_acc(self, true_targets, predicted_targets):\n",
        "      errors = []\n",
        "      for true, pred in zip(true_targets, predicted_targets):\n",
        "        error = true - pred\n",
        "        errors.append(error)\n",
        "      \n",
        "      accuracy = np.mean(errors)\n",
        "      return accuracy\n"
      ],
      "metadata": {
        "id": "s-kAndK44QK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test \n",
        "mlp = MultilayerPerceptron(relu_v, relu_deriv_v, 2, 128)\n",
        "\n",
        "mlp.fit(X_train_vect[0:8], y_train_arr[0:8], 0.01, 5)\n",
        "\n"
      ],
      "metadata": {
        "id": "zZQ51P0LczBi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de354cbf-51ff-462d-e591-d9474212962b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.09189068 0.09576597 0.09189068 0.09362778 0.09189068 0.09307197\n",
            " 0.09189068 0.11770435 0.14037655 0.09189068]\n",
            "2.3871557229002267\n",
            "[1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e+00 1.e-09]\n",
            "20.72326583694641\n",
            "[1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e+00 1.e-09]\n",
            "20.72326583694641\n",
            "[1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e+00 1.e-09]\n",
            "20.72326583694641\n",
            "[1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 5.e-01 5.e-01]\n",
            "20.72326583694641\n",
            "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n",
            "2.3025850929940455\n",
            "[1.25e-01 1.25e-01 1.25e-01 1.25e-01 1.25e-01 1.25e-01 1.25e-01 1.25e-01\n",
            " 1.00e-09 1.00e-09]\n",
            "2.0794415416798357\n",
            "[1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09]\n",
            "20.72326583694641\n",
            "[1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09]\n",
            "20.72326583694641\n",
            "[1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09]\n",
            "20.72326583694641\n",
            "[1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09]\n",
            "20.72326583694641\n",
            "[1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09]\n",
            "20.72326583694641\n",
            "[1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09]\n",
            "20.72326583694641\n",
            "[1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09]\n",
            "20.72326583694641\n",
            "[1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09]\n",
            "20.72326583694641\n",
            "[1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09]\n",
            "20.72326583694641\n",
            "[1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09]\n",
            "20.72326583694641\n",
            "[1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09]\n",
            "20.72326583694641\n",
            "[1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09]\n",
            "20.72326583694641\n",
            "[1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09]\n",
            "20.72326583694641\n",
            "[1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09]\n",
            "20.72326583694641\n",
            "[1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09]\n",
            "20.72326583694641\n",
            "[1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09]\n",
            "20.72326583694641\n",
            "[1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09]\n",
            "20.72326583694641\n",
            "[1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09]\n",
            "20.72326583694641\n",
            "[1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09]\n",
            "20.72326583694641\n",
            "[1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09]\n",
            "20.72326583694641\n",
            "[1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09]\n",
            "20.72326583694641\n",
            "[1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09]\n",
            "20.72326583694641\n",
            "[1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09]\n",
            "20.72326583694641\n",
            "[1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09]\n",
            "20.72326583694641\n",
            "[1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09]\n",
            "20.72326583694641\n",
            "[1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09]\n",
            "20.72326583694641\n",
            "[1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09]\n",
            "20.72326583694641\n",
            "[1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09]\n",
            "20.72326583694641\n",
            "[1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09]\n",
            "20.72326583694641\n",
            "[1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09]\n",
            "20.72326583694641\n",
            "[1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09]\n",
            "20.72326583694641\n",
            "[1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09]\n",
            "20.72326583694641\n",
            "[1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09 1.e-09]\n",
            "20.72326583694641\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: RuntimeWarning: invalid value encountered in subtract\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(relu_v(-5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kL2bLlfJzHIa",
        "outputId": "55985a1f-6b66-4f3b-c412-6a68bf5dd0ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predictions do not work and give NAN \n",
        "output = mlp.forward_propagate(X_test_vect[0])\n",
        "print(output)\n",
        "print(y_test[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRMNq2pSRsc5",
        "outputId": "d727cdd2-5bc5-4bb5-da48-296e4d507e3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3.13148535e+20 3.19816838e+26 1.37065676e+26 4.23188602e+22\n",
            " 7.28038904e+22 9.25516013e+26 1.77814649e+26 2.12401458e+21\n",
            " 2.84044379e+25 1.22440152e+27 3.13075925e+26 2.17924804e+26\n",
            " 7.40114087e+26 1.34004616e+27 1.88732163e+22 3.04362517e+27\n",
            " 5.89393557e+26 6.51230610e+25 1.63550560e+22 0.00000000e+00\n",
            " 1.02765935e+27 9.56784536e+26 0.00000000e+00 1.39443727e+27\n",
            " 8.08627773e+26 5.76486198e+25 9.91134163e+22 2.44955174e+22\n",
            " 1.64599333e+27 3.81989285e+16 3.10080551e+26 1.14545021e+27\n",
            " 3.81335943e+22 5.00501730e+22 3.53027172e+22 6.51173187e+25\n",
            " 9.72157920e+26 1.43347954e+17 2.53426384e+25 2.17700692e+25\n",
            " 1.66560694e+23 6.20073342e+12 1.40060312e+23 2.28721255e+22\n",
            " 0.00000000e+00 1.10640692e+27 0.00000000e+00 4.46862798e+25\n",
            " 1.25451531e+26 1.40484333e+23 5.07688325e+25 9.58971819e+25\n",
            " 4.49812160e+22 0.00000000e+00 1.10111101e+23 0.00000000e+00\n",
            " 2.62293423e+22 1.73896358e+27 5.95101797e+22 1.54347327e+27\n",
            " 6.84417185e+26 1.61660066e+23 1.88464147e+27 1.34662287e+22\n",
            " 3.32897027e+16 1.25088632e+24 0.00000000e+00 1.20230126e+22\n",
            " 3.34661469e+26 4.44165539e+22 8.82337282e+25 0.00000000e+00\n",
            " 1.26885486e+26 6.22061077e+25 3.36842794e+17 8.94096670e+25\n",
            " 7.39902741e+26 2.32928341e+22 1.43882157e+23 1.05047746e+26\n",
            " 3.61955425e+22 1.84176546e+27 1.22441680e+26 3.94413924e+26\n",
            " 0.00000000e+00 1.13321406e+27 7.81411972e+25 7.09036406e+22\n",
            " 3.14486542e+25 9.38032263e+22 9.57140663e+16 1.05989755e+26\n",
            " 8.77808517e+22 1.20303604e+27 1.70205539e+27 0.00000000e+00\n",
            " 3.83546463e+26 1.10569809e+27 4.04210410e+26 3.74497108e+25\n",
            " 5.92383108e+26 2.49678798e+26 4.05214770e+25 2.92227386e+25\n",
            " 1.01310304e+27 1.30790627e+27 9.03613552e+25 2.18017328e+26\n",
            " 7.66931028e+17 2.34287430e+26 5.64859151e+26 3.28989520e+22\n",
            " 6.79132332e+22 1.87894620e+16 2.33288893e+25 0.00000000e+00\n",
            " 5.89835781e+25 3.89075833e+26 2.12399281e+26 4.99225894e+25\n",
            " 1.45773674e+23 0.00000000e+00 7.02861023e+26 2.39466008e+27\n",
            " 1.43038669e+27 8.08043987e+22 3.01598341e+26 4.35287011e+25]\n",
            "[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 9.46706272e+33 0.00000000e+00\n",
            " 0.00000000e+00 4.59211553e+33 5.29221534e+33 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 2.38700556e+33\n",
            " 0.00000000e+00 0.00000000e+00 1.45177920e+34 0.00000000e+00\n",
            " 6.04492102e+33 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.95339842e+33\n",
            " 0.00000000e+00 0.00000000e+00 2.76124773e+33 3.29283351e+33\n",
            " 0.00000000e+00 0.00000000e+00 4.58500668e+33 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 4.66701665e+33\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.34891623e+34\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 1.53044707e+34 0.00000000e+00 2.35838859e+33 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 1.79220162e+34 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 3.49136475e+33\n",
            " 0.00000000e+00 0.00000000e+00 1.74891883e+34 0.00000000e+00\n",
            " 2.84625920e+33 2.07583953e+33 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 1.05317913e+34 0.00000000e+00\n",
            " 0.00000000e+00 1.28955744e+34 0.00000000e+00 6.11367579e+33\n",
            " 3.42731549e+32 0.00000000e+00 4.44863650e+33 6.63812563e+33\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 4.71678335e+33\n",
            " 0.00000000e+00 9.78330401e+33 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 2.53215579e+34 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 1.29475446e+34 0.00000000e+00\n",
            " 1.77951835e+33 9.98366224e+33 0.00000000e+00 0.00000000e+00\n",
            " 0.00000000e+00 0.00000000e+00 5.80357195e+33 0.00000000e+00\n",
            " 1.49500075e+33 0.00000000e+00 0.00000000e+00 1.49916203e+33]\n",
            "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8pOnV8ICeMPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from random import random\n",
        "items = np.array([[random()/2 for _ in range(2)] for _ in range(1000)])\n",
        "targets = np.array([[i[0] + i[1]] for i in items])\n",
        "\n",
        "mlp2 = MultilayerPerceptron(relu_v, relu_deriv_v, 2, 5)\n",
        "\n",
        "mlp2.fit(items, targets, 0.01, 50)\n",
        "\n",
        "# create dummy data\n",
        "inputss = np.array([0.3, 0.1])\n",
        "target = np.array([0.4])\n",
        "\n",
        "# get a prediction\n",
        "output = mlp2.forward_propagate(inputss)\n",
        "\n",
        "print()\n",
        "print(\"Our network believes that {} + {} is equal to {}\".format(inputss[0], inputss[1], output[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNyEtY5tTKnC",
        "outputId": "d852a886-31f7-4f4d-c751-2d4dd6ea8b02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Our network believes that 0.3 + 0.1 is equal to 4.68012593395759e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " model = Sequential()\n",
        " model.add(Conv2D(32, (5, 5), input_shape=(28, 28, 1),    \n",
        "  activation='relu'))\n",
        " model.add(MaxPooling2D())\n",
        " model.add(Dropout(0.2))\n",
        " model.add(Flatten())\n",
        " model.add(Dense(1, activation='relu'))\n",
        " model.add(Dense(1, activation='softmax'))\n",
        "\n",
        " model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "teehUxeLGvnX",
        "outputId": "bfb0db35-589a-4cb7-b70b-c5871f0bbdf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "109/300 [=========>....................] - ETA: 15s - loss: 0.0000e+00 - accuracy: 0.0987"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-5885df133588>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), padding=\"Same\", activation=\"relu\", input_shape=[28, 28, 1]))\n",
        "#model.add(MaxPooling2D())\n",
        "#model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding=\"Same\", activation=\"relu\"))\n",
        "#model.add(MaxPooling2D())\n",
        "#model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "#model.add(Dropout(0.5))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=200)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        },
        "id": "yYFtJHzs-lV-",
        "outputId": "25e6d17b-f9d4-4f18-f545-14eeff5d43ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-ace22312e0de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 919, in compute_loss\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 1790, in categorical_crossentropy\n        y_true, y_pred, from_logits=from_logits, axis=axis)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/backend.py\", line 5083, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (200, 1) and (200, 128) are incompatible\n"
          ]
        }
      ]
    }
  ]
}